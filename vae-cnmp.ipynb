{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angular size : (18, 20, 1), | EEG Chunk size (18, 20, 16, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt, iirnotch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#read trajectory data\n",
    "def resample(data, target_length):\n",
    "    ori_indices = np.arange(len(data))\n",
    "    new_indices = np.linspace(0, len(data) - 1, target_length)\n",
    "    return np.interp(new_indices, ori_indices, data)\n",
    "\n",
    "\n",
    "def bw_bandpass(data, lowcut, highcut, fs, order = 2):\n",
    "    nyquist = fs * 0.5\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype = 'band', output = 'ba', analog = False)\n",
    "    return filtfilt(b, a, data, axis = 1)\n",
    "\n",
    "def bw_notch5060(data, fs, order = 2):\n",
    "    nyquist = fs * 0.5\n",
    "    bp50 = np.array([49.0, 51.0]) / nyquist\n",
    "    bp60 = np.array([59.0, 61.0]) / nyquist\n",
    "\n",
    "    b, a = butter(order, bp50, btype = 'bandstop', output = 'ba', analog = False)\n",
    "    data = filtfilt(b, a, data, axis = 1)\n",
    "\n",
    "    b, a = butter(order, bp60, btype = 'bandstop', output = 'ba', analog = False)\n",
    "    data = filtfilt(b, a, data, axis = 1)\n",
    "    return data\n",
    "\n",
    "#create a pair of timestamp with 15 dp eeg window (prior to target angular)\n",
    "def extract_eeg_chunks(ts, eegs):\n",
    "    offset_index = 250 # offset time 2s, fs = 125, 15 point grouping\n",
    "    len_group = 16 #calculate from angular data\n",
    "    chunks = np.array([])\n",
    "    for t in np.round(ts * fs) + offset_index:\n",
    "        index = int(t[0])\n",
    "        c = eegs[:, index - len_group:index]\n",
    "        c = np.expand_dims(c, 0)\n",
    "        chunks = np.concatenate([chunks, c], axis= 0) if chunks.size else c\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def norm(x):\n",
    "    scaler =  MinMaxScaler((0,1))\n",
    "    ori_dim = x.shape\n",
    "    norm_x = scaler.fit_transform(x.reshape(x.shape[0]*x.shape[1], x.shape[2]))\n",
    "    return norm_x.reshape(ori_dim)\n",
    "\n",
    "\n",
    "chs_map = {0: 'FP1', 1: 'FP2', 2: 'C3', 3: 'C4', 4: 'T5', 5: \n",
    "                        'T6', 6: 'O1', 7: 'O2', 8: 'P4', 9: 'P3', 10: 'T4', 11: 'T3', 12: 'F4', 13: 'F3', 14: 'F8', 15: 'F7'}\n",
    "\n",
    "\n",
    "RESAMPLE_SIZE = 20\n",
    "fs = 125\n",
    "angs_path = os.path.join(os.getcwd(), 'outputs','*ANGLE*') #repalce to the directory\n",
    "angs_files = glob(angs_path)\n",
    "\n",
    "eeg_path = os.path.join(os.getcwd(), 'outputs','*EEG*') #repalce to the directory\n",
    "eeg_files = glob(eeg_path)\n",
    "\n",
    "angs = np.array([]) #angular data of each trial in (trial, sample, 1)\n",
    "trial_eegs = np.array([]) #eeg signal of each trial (trial, sample, dp)\n",
    "chunks_eeg = np.array([]) #chunks of eeg assosicated with timestamp, (trial, sample, chs, dp)\n",
    "eegs = np.array([])\n",
    "\n",
    "for fa,fe in zip(angs_files, eeg_files):\n",
    "    tmp_a = np.load(fa)\n",
    "    tmp_e = np.load(fe)[1:17]\n",
    "\n",
    "    tmp_e = tmp_e - np.mean(tmp_e) #remove dc offset\n",
    "    tmp_e = bw_notch5060(tmp_e, 125) #apply notch\n",
    "    tmp_e  = bw_bandpass(tmp_e, 1.0, 40.1, 125, 2) #filter\n",
    "    tmp_e = tmp_e[:, 0:600]\n",
    "    # print(tmp[:,0].shape)\n",
    "    ang = np.expand_dims(resample(tmp_a[:,0], RESAMPLE_SIZE), [0,-1])\n",
    "    ts = np.expand_dims(resample(tmp_a[:,1], RESAMPLE_SIZE),[0, -1])\n",
    "    \n",
    "    ts = (ts - ts.min()) * 10**-9 #$time stamp is in nano second\n",
    "    eeg = np.expand_dims(tmp_e, 0)\n",
    "    if 1.9 <= ts.max() - ts.min() <= 2.1: #filter only feasible trajectories\n",
    "        angs = np.concatenate([angs, ang], axis = 0) if angs.size else ang\n",
    "        eegs = np.concatenate([eegs, eeg], axis = 0) if eegs.size else eeg\n",
    "\n",
    "for eeg, ts in zip(eegs, timestamp):\n",
    "    chunks = np.expand_dims(extract_eeg_chunks(ts, eeg),[0, -1])\n",
    "    chunks_eeg = np.concatenate([chunks_eeg, chunks]) if chunks_eeg.size else chunks\n",
    "\n",
    "angs = norm(angs)\n",
    "print(f\"Angular size : {angs.shape}, | EEG Chunk size {chunks_eeg.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_max = 10\n",
    "train_N = 14\n",
    "train_p = np.random.permutation(15)\n",
    "\n",
    "def get_train_sample(eegs, angs, obs_len):\n",
    "    n = np.random.randint(0,obs_max)+1\n",
    "    d = train_p[np.random.randint(0, train_N)]\n",
    "\n",
    "    #create timestamp vector\n",
    "    times = np.linspace(0, 1, obs_len)\n",
    "    perm = np.random.permutation(obs_len)\n",
    "    obs_eeg = np.zeros((n, 16, 16, 2))\n",
    "    target_t = np.zeros((1,1))\n",
    "    target_eeg = np.zeros((1,16,16,2))\n",
    "    for i in range(n):\n",
    "        obs_eeg[i,:,:,0] = np.ones((16,16)) * times[perm[i]]\n",
    "        obs_eeg[i,:,:,1] = eegs[d, i,:,:,0] \n",
    "\n",
    "    target_t[0, 0] = times[n]\n",
    "    target_eeg[0, :,:, 1] = eegs[d, n, :,:, 0]\n",
    "    \n",
    "    return [obs_eeg, target_t], [target_eeg], d, perm[n]\n",
    "# obs, out, _,_ = get_train_sample(chunks_eeg, angs, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test EEG AE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 20, 1), (3, 20, 16, 16), (15, 20, 1), (15, 20, 16, 16))"
      ]
     },
     "execution_count": 785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VARIABLE\n",
    "#data preparatio\n",
    "test_eeg_ec_data = chunks_eeg[:, :, :, :] #test single channel , C3\n",
    "\n",
    "X = timestamp[:15,:,:]#time\n",
    "Y = test_eeg_ec_data[:15,:,:] #eeg\n",
    "\n",
    "v_X = timestamp[15:]\n",
    "v_Y = test_eeg_ec_data[15:]\n",
    "\n",
    "obs_max = 5 #max observation range\n",
    "d_N = X.shape[0] #nbr of observation\n",
    "d_x, d_y = X.shape[-1], Y.shape[-1] #depth?\n",
    "time_len = X.shape[1]\n",
    "\n",
    "v_X.shape, v_Y.shape, X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0][2], Y[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as D\n",
    "import torch.optim as optim\n",
    "\n",
    "def get_train_sample_eeg():\n",
    "    n = np.random.randint(0,obs_max)+1\n",
    "    d = np.random.randint(0, d_N)\n",
    "\n",
    "    observations = np.zeros((1, n, 2, 15))\n",
    "    target_X = np.zeros((1,d_y))\n",
    "    target_Y = np.zeros((1,d_y))\n",
    "\n",
    "    # print(observations.shape, test_eeg_ec_data.shape)\n",
    "    perm = np.random.permutation(time_len) #random timepoint\n",
    "\n",
    "    # Y[d, perm[:n]].shape, Y[d, perm[:n]][0], times[0]\n",
    "    # X[d,perm[:n]].shape, Y[d, perm[:n]].shape\n",
    "    times = np.repeat(X[d, perm[:n]], d_y, axis = 1)\n",
    "    signal = Y[d, perm[:n]]\n",
    "\n",
    "    # X[d,perm[:n]].shape, Y[d, perm[:n]].shape, times.shape\n",
    "    for i in range(n):\n",
    "        observations[0, i, 0, :] = times[i]\n",
    "        observations[0, i, 1, :] = signal[i]\n",
    "\n",
    "    target_X[0] = np.repeat(X[d,perm[n]], Y.shape[-1])\n",
    "    target_Y[0] = Y[d,perm[n]]\n",
    "\n",
    "    return torch.from_numpy(observations), torch.from_numpy(target_X), torch.from_numpy(target_Y)\n",
    "\n",
    "def predict_model(observations, target_X, plot = True):\n",
    "    predicted_Y = np.zeros((time_len,d_y))\n",
    "    predicted_std = np.zeros((time_len,d_y))\n",
    "    with torch.no_grad():\n",
    "        prediction = model(torch.from_numpy(observations),torch.from_numpy(target_X)).numpy()\n",
    "    predicted_Y = prediction[:,:d_y]\n",
    "    predicted_std = np.log(1+np.exp(prediction[:,d_y:]))\n",
    "    if plot: # We highly recommend that you customize your own plot function, but you can use this function as default\n",
    "        for i in range(d_y): #for every feature in Y vector we are plotting training data and its prediction\n",
    "            fig = plt.figure(figsize=(5,5))\n",
    "            for j in range(d_N):\n",
    "                plt.plot(X[j,:,0],Y[j,:,i]) # assuming X[j,:,0] is time\n",
    "            plt.plot(X[j,:,0],predicted_Y[:,i],color='black')\n",
    "            plt.errorbar(X[j,:,0],predicted_Y[:,i],yerr=predicted_std[:,i],color = 'black',alpha=0.4)\n",
    "            plt.scatter(observations[:,0],observations[:,d_x+i],marker=\"X\",color='black')\n",
    "            plt.show()  \n",
    "    return predicted_Y, predicted_std\n",
    "\n",
    "def log_prob_loss(output, target):\n",
    "    mean, sigma = output.chunk(2, dim = -1)\n",
    "    sigma = F.softplus(sigma)\n",
    "    dist = D.Independent(D.Normal(loc=mean, scale=sigma), 1)\n",
    "    return -torch.mean(dist.log_prob(target))\n",
    "\n",
    "\n",
    "\n",
    "class CNMP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNMP, self).__init__()\n",
    "        \n",
    "        # Encoder takes observations which are (X,Y) tuples and produces latent representations for each of them\n",
    "        self.encoder = nn.Sequential(\n",
    "        nn.Linear(d_y,128),nn.ReLU(),\n",
    "        nn.Linear(128,128),nn.ReLU(),\n",
    "        nn.Linear(128,128)\n",
    "        )\n",
    "        \n",
    "        #Decoder takes the (r_mean, target_t) tuple and produces mean and std values for each dimension of the output\n",
    "        self.decoder = nn.Sequential(\n",
    "        nn.Linear(128+d_x,128),nn.ReLU(),\n",
    "        nn.Linear(128,128),nn.ReLU(),\n",
    "        nn.Linear(128,2*d_y)\n",
    "        )\n",
    "        \n",
    "    def forward(self,observations,target_t):\n",
    "        global dbg\n",
    "        print(observations.shape, target_t.shape)\n",
    "        r = self.encoder(observations) # Generating observations\n",
    "        r_mean = torch.mean(r,dim=0) # Taking mean and generating the general representation\n",
    "        dbg = r_mean\n",
    "        print(r_mean.shape)\n",
    "        r_mean = r_mean.repeat(target_t.shape[0],1) # Duplicating general representation for every target_t\n",
    "\n",
    "        concat = torch.cat((r_mean,target_t),dim=-1) # Concatenating each target_t with general representation\n",
    "        output = self.decoder(concat) # Producing mean and std values for each target_t\n",
    "        return output\n",
    "dbg = None\n",
    "model = CNMP().double()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    obs, targett, targetout = get_train_sample_eeg()\n",
    "    print(targetout.shape, targett.shape)\n",
    "    out = model(obs, targett)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "from IPython.core.display import HTML\n",
    "from IPython.core.display import display as html_width\n",
    "\n",
    "model = CNMP().double()\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "smooth_losses = [0]\n",
    "losses = []\n",
    "loss_checkpoint = 1000\n",
    "plot_checkpoint = 1000\n",
    "validation_checkpoint = 100\n",
    "validation_error = 9999999\n",
    "\n",
    "for step in range(1000000):  # loop over the dataset multiple times\n",
    "    observations, target_t, target_output = get_train_sample_eeg()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output = model(observations, target_t)\n",
    "    loss = log_prob_loss(output, target_output)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % loss_checkpoint == 0:\n",
    "        losses.append(loss.data)\n",
    "        smooth_losses[-1] += loss.data/(plot_checkpoint/loss_checkpoint)\n",
    "    \n",
    "    if step % validation_checkpoint == 0:\n",
    "        current_error = 0\n",
    "        for i in range(v_X.shape[0]):\n",
    "            predicted_Y,predicted_std = predict_model(np.array([np.concatenate((v_X[i,0],v_Y[i,0]))]), v_X[i], plot= False)\n",
    "            current_error += np.mean((predicted_Y - v_Y[i,:])**2) / v_X.shape[0]\n",
    "        if current_error < validation_error:\n",
    "            validation_error = current_error\n",
    "            torch.save(model.state_dict(), 'cnmp_best_validation.h5')\n",
    "            print(' New validation best. Error is ', current_error)\n",
    "        \n",
    "    if step % plot_checkpoint == 0:\n",
    "        #clearing output cell\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(pl.gcf())\n",
    "        \n",
    "        print(step)\n",
    "        #plotting training examples and smoothed losses\n",
    "        \n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.subplot(121)\n",
    "        plt.title('Train Loss')\n",
    "        plt.plot(range(len(losses)),losses)\n",
    "        plt.subplot(122)\n",
    "        plt.title('Train Loss (Smoothed)')\n",
    "        plt.plot(range(len(smooth_losses)),smooth_losses)\n",
    "        plt.show()\n",
    "        \n",
    "        #plotting validation cases\n",
    "        for i in range(v_X.shape[0]):\n",
    "            predict_model(np.array([np.concatenate((v_X[i,0],v_Y[i,0]))]), v_X[i])\n",
    "        \n",
    "        if step!=0:\n",
    "            smooth_losses.append(0)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arm-tracking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
